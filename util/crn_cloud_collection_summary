#!/bin/bash

set -eEuo pipefail

usage() {
cat << EOF

  Track the ASAP raw/curated buckets, size, sample breakdown, and subject breakdown in the CRN Cloud.
  Note:
  - Raw bucket sizes include files that are used for development
  - Storage size used for this project is much larger since unreleased data is stored in there as well and cross-team cohort data
  - Sample and subject breakdown is ongoing as more data modalities are being added
  - Samples included in the same data modality does NOT mean all samples went through curation

  Usage: $0 [OPTIONS]

  OPTIONS
    -h  Display this message and exit
    -s  Grab no. of samples and subjects only

EOF
}

SAMPLES_SUBJECTS_ONLY=false

while getopts ":hs" OPTION; do
  case ${OPTION} in
    h) usage; exit 1;;
    s) SAMPLES_SUBJECTS_ONLY=true;;
  esac
done


dnastack use cloud.parkinsonsroadmap.org
INDIVIDUAL_DATASETS=$(dnastack collections list | jq -r '.[] | select(.tags[]?.label == "Individual Dataset") | .slugName')
COHORT_DATASETS=$(dnastack collections list | jq -r '.[] | select(.tags[]?.label == "Harmonized Collection") | .slugName')

echo "Got "$(echo "$INDIVIDUAL_DATASETS" | wc -l | tr -d '[:space:]')" individual datasets from CRN Cloud"
echo "Got "$(echo "$COHORT_DATASETS" | wc -l | tr -d '[:space:]')" harmonized collections from CRN Cloud"

date_str=$(date +"%Y-%m-%d")
output_file="crn_cloud_collection_summary.$date_str.tsv"
echo -e "gcp_raw_bucket\tgcp_raw_bucket_size\tgcp_curated_bucket\tgcp_curated_bucket_size\tsample_count\tsubject_count\tteam_name\tbrain_sample_count\tbrain_region_count\tbrain_donor_count" > "$output_file"

unique_teams=""
unique_brain_regions=""

while IFS= read -r slug; do
    underscored_slug="${slug//-/_}"

    # Split slug into parts
    IFS='-' read -r -a parts <<< "$slug"

    if [[ "${parts[0]}" == "prod" && "${parts[1]}" == "team" ]]; then
        team_name="${parts[2]}"
    elif [[ "${parts[0]}" == "prod" ]]; then
        team_name="${parts[1]}"
    else
        echo "Cannot parse team name for slug: $slug" >&2
        continue
    fi

    echo "Detected [$slug] for team [$team_name]..."
    
    # Track unique teams
    if ! echo "$unique_teams" | grep -qw "$team_name"; then
        unique_teams="$unique_teams $team_name"
    fi

    echo "Check if DATA table exists..."
    collection_tables=$(dnastack collections query -c "$slug" \
        "SELECT table_name FROM collections.information_schema.tables 
        WHERE table_schema = '$underscored_slug'" \
        -o csv)
    if ! echo "$collection_tables" | grep -q "data"; then
        echo "DATA table does not exist, guessing raw bucket..."
        gcp_raw_bucket=$(echo "$slug" | sed 's;prod-;gs://asap-raw-;g')
        if gcloud storage buckets describe "$gcp_raw_bucket" >/dev/null 2>&1; then
            echo "Bucket exists; continuing"
        else
            echo "[WARNING] Bucket does NOT exist: ["$gcp_raw_bucket"]; skipping"
            continue
        fi
    else
        echo "DATA table exists, getting GCP raw bucket name"
        gcp_raw_uri=$(dnastack collections query -c "$slug" \
            "SELECT gcp_uri FROM \"collections\".\"$underscored_slug\".\"${team_name}_data\" LIMIT 1" \
            -o csv)
        gcp_raw_bucket=$(echo "$gcp_raw_uri" | cut -d'/' -f1-3 | tail -n +2)
        # Exception - some datasets do not have gs uri's in their DATA.csv
        if [[ "$gcp_raw_bucket" != gs://* ]]; then
            echo "[$slug] DATA.csv does not have gcp_uri"
            echo "Trying to grab bucket name from slug..."
            gcp_raw_bucket=$(echo "$slug" | sed 's;prod-;gs://asap-raw-;g')
            if gcloud storage buckets describe "$gcp_raw_bucket" >/dev/null 2>&1; then
                echo "Bucket exists; continuing"
            else
                echo "[WARNING] Bucket does NOT exist: ["$gcp_raw_bucket"]; skipping"
                continue
            fi
        fi
    fi

    echo "Getting GCP curated bucket name"
    gcp_prod_bucket=$(echo $gcp_raw_bucket | sed 's/raw/curated/g')

    echo "Getting # of samples"
    sample_count=$(dnastack collections query -c "$slug" \
        "SELECT COUNT(DISTINCT asap_sample_id) AS sample_count FROM \"collections\".\"$underscored_slug\".\"${team_name}_sample\"" \
        -o csv \
        | tail -n +2 | tr -d '[:space:]')

    echo "Getting # of subjects"
    subject_count=$(dnastack collections query -c "$slug" \
        "SELECT COUNT(DISTINCT subject_id) AS subject_count FROM \"collections\".\"$underscored_slug\".\"${team_name}_sample\"" \
        -o csv \
        | tail -n +2 | tr -d '[:space:]')

    # Check for PMDBS table, CLINPATH table, and get brain-specific stats
    brain_sample_count="NA"
    brain_region_count="NA"

    echo "Checking for PMDBS table..."
    if echo "$collection_tables" | grep -qi "pmdbs"; then
        echo "PMDBS table found, getting brain sample count..."
        brain_sample_count=$(dnastack collections query -c "$slug" \
            "SELECT COUNT(DISTINCT asap_sample_id) AS brain_sample_count FROM \"collections\".\"$underscored_slug\".\"${team_name}_pmdbs\"" \
            -o csv \
            | tail -n +2 | tr -d '[:space:]')
        echo "PMDBS brain sample count: $brain_sample_count"
        
        echo "Getting unique brain regions..."
        brain_regions=$(dnastack collections query -c "$slug" \
            "SELECT DISTINCT brain_region FROM \"collections\".\"$underscored_slug\".\"${team_name}_pmdbs\" WHERE brain_region IS NOT NULL" \
            -o csv \
            | tail -n +2)
        region_count=0
        while IFS= read -r region; do
            if [[ -n "$region" ]]; then
                if ! echo "$unique_brain_regions" | grep -qF "$region"; then
                    unique_brain_regions="$unique_brain_regions|$region"
                fi
                ((region_count++))
            fi
        done <<< "$brain_regions"
        brain_region_count=$region_count
        echo "Brain region count for this collection: [$brain_region_count]"
    else
        echo "No PMDBS table found, checking SAMPLE table for brain tissue..."
        brain_tissue_count=$(dnastack collections query -c "$slug" \
            "SELECT COUNT(DISTINCT asap_sample_id) FROM \"collections\".\"$underscored_slug\".\"${team_name}_sample\" WHERE LOWER(tissue) LIKE '%brain%'" \
            -o csv \
            | tail -n +2 | tr -d '[:space:]')
        if [[ "$brain_tissue_count" =~ ^[0-9]+$ ]] && [[ "$brain_tissue_count" -gt 0 ]]; then
            brain_sample_count=$brain_tissue_count
            echo "Found [$brain_sample_count] brain samples from SAMPLE.tissue column"
        else
            echo "No brain samples found in SAMPLE table"
        fi
    fi

    brain_donor_count="NA"

    echo "Checking for CLINPATH table..."
    if echo "$collection_tables" | grep -qi "clinpath"; then
        echo "CLINPATH table found, getting brain donor count..."
        brain_donor_count=$(dnastack collections query -c "$slug" \
            "SELECT COUNT(DISTINCT subject_id) AS brain_donor_count FROM \"collections\".\"$underscored_slug\".\"${team_name}_clinpath\"" \
            -o csv \
            | tail -n +2 | tr -d '[:space:]')
        echo "Brain donor count: $brain_donor_count"
    else
        echo "No CLINPATH table found for this collection"
    fi

    if "${SAMPLES_SUBJECTS_ONLY}"; then
        gcp_raw_bucket_size="NA"
        gcp_prod_bucket_size="NA"
    else
        echo "Getting GCP raw bucket size"
        gcp_raw_bucket_size=$(gcloud storage du -s "$gcp_raw_bucket" | grep -oE '^[0-9]+')

        echo "Getting GCP curated bucket size"
        gcp_prod_bucket_size=$(gcloud storage du -s "$gcp_prod_bucket" | grep -oE '^[0-9]+')
    fi

    echo -e "${gcp_raw_bucket}\t${gcp_raw_bucket_size}\t${gcp_prod_bucket}\t${gcp_prod_bucket_size}\t${sample_count}\t${subject_count}\t${team_name}\t${brain_sample_count}\t${brain_region_count}\t${brain_donor_count}" >> "$output_file"
done <<< "$INDIVIDUAL_DATASETS"

# Clean up
sed "s/[[:space:]]*$//" "$output_file" | tr -d "\r" > temp.tsv && mv temp.tsv "$output_file"

calculate_breakdown() {
    local output_file="$1"
    local count_type="$2"  # "sample" or "subject"
    
    echo "Calculating the ${count_type} breakdown"
    awk -F'\t' -v count_type="$count_type" '
    NR==1 {
        count_col_name = count_type "_count"
        for (i=1; i<=NF; i++) {
            if ($i == count_col_name) count_col = i
            if ($i == "gcp_raw_bucket") bucket_col = i
        }
        next
    }
    NR>1 {
        count = $count_col
        bucket = $bucket_col
        total_count += count
        
        # Data modality grouping logic
        if (bucket ~ /sc-rnaseq/ || bucket ~ /sn-rnaseq/) {
            grp["sc_sn"] += count
        } else if (bucket ~ /bulk-rnaseq/) {
            grp["bulk"] += count
        } else if (bucket ~ /spatial/) {
            grp["spatial"] += count
        } else if (bucket ~ /ms-p/) {
            grp["ms_p"] += count
        } else if (bucket ~ /parsebio/) {
            grp["parsebio"] += count
        } else if (bucket ~ /multimodal/) {
            grp["multimodal"] += count
        } else if (bucket ~ /metagenome/) {
            grp["metagenomics"] += count
        } else {
            grp["other"] += count
            other_buckets[bucket] = 1
        }
        
        # Data origin grouping logic
        if (bucket ~ /human/ || bucket ~ /pmdbs/) {
            origin["human"] += count
        } else if (bucket ~ /mouse/) {
            origin["mouse"] += count
        } else if (bucket ~ /cell/ || bucket ~ /invitro/ || bucket ~ /ipsc/) {
            origin["cell"] += count
        } else {
            origin["other"] += count
            origin_other_buckets[bucket] = 1
        }
    }
    END {
        printf "=== %s COUNT SUMMARY ===\n", toupper(count_type)
        printf "Total %ss: %d\n", count_type, total_count
        print ""
        
        print "=== BREAKDOWN BY DATA TYPE ==="
        printf "sc/sn RNAseq: %d\n", grp["sc_sn"]
        printf "bulk RNAseq:  %d\n", grp["bulk"]
        printf "spatial:      %d\n", grp["spatial"]
        printf "proteomics:   %d\n", grp["ms_p"]
        printf "parsebio:     %d\n", grp["parsebio"]
        printf "multimodal:   %d\n", grp["multimodal"]
        printf "metagenomics: %d\n", grp["metagenomics"]
        printf "other:        %d\n", grp["other"]
        print ""
        
        print "=== BUCKETS IN \"OTHER\" DATA MODALITY GROUP ==="
        if (length(other_buckets) > 0) {
            for (b in other_buckets) {
                print b
            }
            print ""
        }
        
        printf "=== %s ORIGIN BREAKDOWN ===\n", toupper(count_type)
        printf "human:        %d\n", origin["human"]
        printf "mouse:        %d\n", origin["mouse"]
        printf "cell:         %d\n", origin["cell"]
        printf "other:        %d\n", origin["other"]
        print ""
        
        print "=== BUCKETS IN \"OTHER\" ORIGIN GROUP ==="
        if (length(origin_other_buckets) > 0) {
            for (b in origin_other_buckets) {
                print b
            }
        }
    }
    ' "$output_file"
}

calculate_breakdown "$output_file" "sample"
echo ""
echo "========================================"
echo ""
calculate_breakdown "$output_file" "subject"

if ! "${SAMPLES_SUBJECTS_ONLY}"; then
    echo "Calculating the total size of raw and curated buckets"
    awk -F'\t' '
    NR==1 {
        for(i=1;i<=NF;i++){
            if($i=="gcp_raw_bucket_size") raw_col=i
            if($i=="gcp_curated_bucket_size") prod_col=i
        }
        next
    }

    NR>1 {
        if (raw_col > 0) total_raw += $raw_col
        if (prod_col > 0) total_prod += $prod_col
    }

    END {
        tb_raw  = total_raw  / (1024^4)
        tb_prod = total_prod / (1024^4)
        tb_grand = (total_raw + total_prod) / (1024^4)

        print "=== BUCKET SIZE SUMMARY ==="
        printf "Total raw size (TB):   %.1f\n", tb_raw
        printf "Total prod size (TB):  %.1f\n", tb_prod
        printf "Grand total (TB):      %.1f\n", tb_grand
    }' "$output_file"
fi

# Calculate brain sample totals by origin and brain donors from output file
echo ""
echo "========================================"
awk -F'\t' '
NR==1 {
    for(i=1;i<=NF;i++) {
        if($i=="brain_sample_count") brain_col=i
        if($i=="brain_donor_count") donor_col=i
        if($i=="gcp_raw_bucket") bucket_col=i
    }
    next
}
NR>1 {
    if ($brain_col!="NA" && $brain_col~/^[0-9]+$/) {
        brain_count = $brain_col
        bucket = $bucket_col
        total_brain += brain_count
        
        # Data origin grouping logic (same as sample/subject breakdown)
        if (bucket ~ /human/ || bucket ~ /pmdbs/) {
            origin["human"] += brain_count
        } else if (bucket ~ /mouse/) {
            origin["mouse"] += brain_count
        } else if (bucket ~ /cell/ || bucket ~ /invitro/ || bucket ~ /ipsc/) {
            origin["cell"] += brain_count
        } else {
            origin["other"] += brain_count
        }
    }
    
    # Count brain donors
    if (donor_col > 0 && $donor_col!="NA" && $donor_col~/^[0-9]+$/) {
        total_donors += $donor_col
    }
}
END {
    print "=== BRAIN SAMPLE ORIGIN BREAKDOWN ==="
    printf "human:        %d\n", origin["human"]
    printf "mouse:        %d\n", origin["mouse"]
    printf "cell:         %d\n", origin["cell"]
    printf "other:        %d\n", origin["other"]
    printf "Total brain samples: %d\n", total_brain
    print ""
    printf "Total brain donors (CLINPATH): %d\n", total_donors
}' "$output_file"
echo ""
echo "========================================"
echo "=== ADDITIONAL STATISTICS ==="
team_count=$(echo "$unique_teams" | wc -w | tr -d '[:space:]')
echo "Total unique teams contributing: $team_count"
echo "Teams:$unique_teams"
echo ""
region_count=$(echo "$unique_brain_regions" | tr '|' '\n' | grep -v '^$' | wc -l | tr -d '[:space:]')
echo "Total unique brain regions (PMDBS only): $region_count"
if [ -n "$unique_brain_regions" ]; then
    echo "Brain regions found:"
    echo "$unique_brain_regions" | tr '|' '\n' | grep -v '^$' | while read -r region; do
        echo "  - $region"
    done
fi
echo ""
echo "Saved results to [$(pwd)/$output_file]"
